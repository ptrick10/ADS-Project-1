{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f43fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/14 11:47:27 WARN Utils: Your hostname, DESKTOP-M8PQ28M resolves to a loopback address: 127.0.1.1; using 192.168.86.205 instead (on interface wifi0)\n",
      "21/08/14 11:47:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/08/14 11:47:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "INFO:SparkMonitorKernel:Client Connected ('127.0.0.1', 54429)\n"
     ]
    }
   ],
   "source": [
    "# Taxi model\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Start the spark context\n",
    "sc = SparkContext.getOrCreate(conf=swan_spark_conf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "372b2748",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Project 1\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "\n",
    "# a nice way of filtering out deprecated warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# start a spark session (from spark tutrial)\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# create a spark session (which will run spark jobs)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d826758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it look nice\n",
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "\n",
    "# make fast\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454f8ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# schema\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "feb_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-02.csv', header=True)\n",
    "\n",
    "ints = ('VendorID', 'passenger_count', 'RatecodeID', 'PULocationID', 'DOLocationID', 'payment_type',)\n",
    "doubles = ('trip_distance', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', \n",
    "           'improvement_surcharge', 'total_amount', 'congestion_surcharge')\n",
    "strings = ('store_and_fwd_flag', )\n",
    "dtimes = ('tpep_pickup_datetime', 'tpep_dropoff_datetime', )\n",
    "\n",
    "dtypes = {column: IntegerType() for column in ints}\n",
    "dtypes.update({column: DoubleType() for column in doubles})\n",
    "dtypes.update({column: StringType() for column in strings})\n",
    "dtypes.update({column: TimestampType() for column in dtimes})\n",
    "schema = StructType()\n",
    "\n",
    "for column in feb_yellow_sdf.columns:\n",
    "    schema.add(column, # column name\n",
    "               dtypes[column], # data type\n",
    "               True # is nullable?\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b79696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data staight into spark dataframe\n",
    "jan_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-01.csv', header=True, schema=schema)\n",
    "feb_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-02.csv', header=True, schema=schema)\n",
    "mar_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-03.csv', header=True, schema=schema)\n",
    "apr_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-04.csv', header=True, schema=schema)\n",
    "may_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-05.csv', header=True, schema=schema)\n",
    "jun_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-06.csv', header=True, schema=schema)\n",
    "jul_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-07.csv', header=True, schema=schema)\n",
    "aug_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-08.csv', header=True, schema=schema)\n",
    "sep_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-09.csv', header=True, schema=schema)\n",
    "oct_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-10.csv', header=True, schema=schema)\n",
    "nov_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-11.csv', header=True, schema=schema)\n",
    "dec_yellow_sdf = spark.read.csv('../Proj1data/yellow_tripdata_2019-12.csv', header=True, schema=schema)\n",
    "\n",
    "jan_yellow_sdf_2020 = spark.read.csv('../Proj1data/yellow_tripdata_2020-01.csv', header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f676c3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine dataframes\n",
    "yellow_data_2019 = jan_yellow_sdf.union(feb_yellow_sdf).union(mar_yellow_sdf).union(apr_yellow_sdf).union(may_yellow_sdf).union(jun_yellow_sdf).union(jul_yellow_sdf).union(aug_yellow_sdf).union(sep_yellow_sdf).union(oct_yellow_sdf).union(nov_yellow_sdf).union(dec_yellow_sdf)\n",
    "# print(yellow_data_2019.count())\n",
    "yellow_data_2019.printSchema()\n",
    "\n",
    "del jan_yellow_sdf\n",
    "del feb_yellow_sdf\n",
    "del mar_yellow_sdf\n",
    "del apr_yellow_sdf\n",
    "del may_yellow_sdf\n",
    "del jun_yellow_sdf\n",
    "del jul_yellow_sdf\n",
    "del aug_yellow_sdf\n",
    "del sep_yellow_sdf\n",
    "del oct_yellow_sdf\n",
    "del nov_yellow_sdf\n",
    "del dec_yellow_sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9467c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(date,DateType,true),StructField(maxTemp,StringType,true)))\n"
     ]
    }
   ],
   "source": [
    "# Engineer features trip time and max temperature\n",
    "'''\n",
    "https://www.andyupton.net/blog/2019/6/12/feature-engineering-with-pyspark\n",
    "'''\n",
    "## Feature engineering\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import to_date, dayofweek\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019.withColumn('trip_time', unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp('tpep_pickup_datetime'))\n",
    "\n",
    "# get max temperature for the day\n",
    "max_temperatures_sdf = spark.read.csv('../Proj1data/maxTemperaturesNYC.csv', header=True)\n",
    "# max_temperatures_sdf.select(to_date(max_temperatures_sdf.date).alias('date'))\n",
    "\n",
    "max_temperatures_sdf = max_temperatures_sdf.withColumn('date', to_date(max_temperatures_sdf['date']))\n",
    "\n",
    "print(max_temperatures_sdf.schema)\n",
    "\n",
    "# add column to yellow data\n",
    "# yellow_data_2019_w_temp = yellow_data_2019.withColumn('max_temp', when(yellow_data_2019.date, dic[date]))\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.withColumn('date', to_date(yellow_data_2019_wtemp_and_time.tpep_pickup_datetime))\n",
    "\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.join(max_temperatures_sdf, on=['date'], how='left_outer')\n",
    "\n",
    "## Same for 2020 \n",
    "max_temperatures_sdf_2020 = spark.read.csv('../Proj1data/maxTemperaturesNYC2020.csv', header=True)\n",
    "max_temperatures_sdf_2020 = max_temperatures_sdf_2020.withColumn('date', to_date(max_temperatures_sdf_2020['date']))\n",
    "\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020.withColumn('trip_time', unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp('tpep_pickup_datetime'))\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.withColumn('date', to_date(jan_yellow_sdf_2020_wtemp_and_time.tpep_pickup_datetime))\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.join(max_temperatures_sdf_2020, on=['date'], how='left_outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f6133f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>date</th><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>trip_time</th><th>maxTemp</th></tr>\n",
       "<tr><td>2020-01-01</td><td>1</td><td>2020-01-01 00:28:15</td><td>2020-01-01 00:33:03</td><td>1</td><td>1.2</td><td>1</td><td>N</td><td>238</td><td>239</td><td>1</td><td>6.0</td><td>3.0</td><td>0.5</td><td>1.47</td><td>0.0</td><td>0.3</td><td>11.27</td><td>2.5</td><td>288</td><td>41.0</td></tr>\n",
       "<tr><td>2020-01-01</td><td>1</td><td>2020-01-01 00:35:39</td><td>2020-01-01 00:43:04</td><td>1</td><td>1.2</td><td>1</td><td>N</td><td>239</td><td>238</td><td>1</td><td>7.0</td><td>3.0</td><td>0.5</td><td>1.5</td><td>0.0</td><td>0.3</td><td>12.3</td><td>2.5</td><td>445</td><td>41.0</td></tr>\n",
       "<tr><td>2020-01-01</td><td>1</td><td>2020-01-01 00:47:41</td><td>2020-01-01 00:53:52</td><td>1</td><td>0.6</td><td>1</td><td>N</td><td>238</td><td>238</td><td>1</td><td>6.0</td><td>3.0</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>10.8</td><td>2.5</td><td>371</td><td>41.0</td></tr>\n",
       "<tr><td>2020-01-01</td><td>1</td><td>2020-01-01 00:55:23</td><td>2020-01-01 01:00:14</td><td>1</td><td>0.8</td><td>1</td><td>N</td><td>238</td><td>151</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.36</td><td>0.0</td><td>0.3</td><td>8.16</td><td>0.0</td><td>291</td><td>41.0</td></tr>\n",
       "<tr><td>2020-01-01</td><td>2</td><td>2020-01-01 00:01:58</td><td>2020-01-01 00:04:16</td><td>1</td><td>0.0</td><td>1</td><td>N</td><td>193</td><td>193</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>4.8</td><td>0.0</td><td>138</td><td>41.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------+\n",
       "|      date|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_time|maxTemp|\n",
       "+----------+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------+\n",
       "|2020-01-01|       1| 2020-01-01 00:28:15|  2020-01-01 00:33:03|              1|          1.2|         1|                 N|         238|         239|           1|        6.0|  3.0|    0.5|      1.47|         0.0|                  0.3|       11.27|                 2.5|      288|   41.0|\n",
       "|2020-01-01|       1| 2020-01-01 00:35:39|  2020-01-01 00:43:04|              1|          1.2|         1|                 N|         239|         238|           1|        7.0|  3.0|    0.5|       1.5|         0.0|                  0.3|        12.3|                 2.5|      445|   41.0|\n",
       "|2020-01-01|       1| 2020-01-01 00:47:41|  2020-01-01 00:53:52|              1|          0.6|         1|                 N|         238|         238|           1|        6.0|  3.0|    0.5|       1.0|         0.0|                  0.3|        10.8|                 2.5|      371|   41.0|\n",
       "|2020-01-01|       1| 2020-01-01 00:55:23|  2020-01-01 01:00:14|              1|          0.8|         1|                 N|         238|         151|           1|        5.5|  0.5|    0.5|      1.36|         0.0|                  0.3|        8.16|                 0.0|      291|   41.0|\n",
       "|2020-01-01|       2| 2020-01-01 00:01:58|  2020-01-01 00:04:16|              1|          0.0|         1|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                 0.0|      138|   41.0|\n",
       "+----------+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+-------+"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan_yellow_sdf_2020_wtemp_and_time.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ef3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change trip time to int for efficiency\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.withColumn('trip_time', yellow_data_2019_wtemp_and_time.trip_time.cast('int'))\n",
    "yellow_data_2019_wtemp_and_time.schema\n",
    "\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.withColumn('trip_time', jan_yellow_sdf_2020_wtemp_and_time.trip_time.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "125d2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data using filter\n",
    "\n",
    "# filter fare amount to be between 0 and 600\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.fare_amount > 0) \n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.fare_amount < 200)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.fare_amount > 0) \n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.fare_amount < 200)\n",
    "\n",
    "# filter trip distance to be between 0 and 150\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.trip_distance > 0)\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.trip_distance < 150)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.trip_distance > 0)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.trip_distance < 150)\n",
    "\n",
    "# filter payment type to be cash or card only\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.payment_type != 3)\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.payment_type != 4)\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.payment_type != 5)\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.payment_type != 6)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.payment_type != 3)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.payment_type != 4)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.payment_type != 5)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.payment_type != 6)\n",
    "\n",
    "# filter so rate code must be standard rate\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.RatecodeID == 1)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.RatecodeID == 1)\n",
    "\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.maxTemp.isNotNull())\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.maxTemp.isNotNull())\n",
    "\n",
    "# no trips an be > 2 hours\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.trip_time > 0)\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.trip_time < 7200)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.trip_time > 0)\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.filter(jan_yellow_sdf_2020_wtemp_and_time.trip_time < 7200)\n",
    "\n",
    "# There also seem to be some dates that are in 2018 instead of 2019. \n",
    "# filter so only 2019 pickup allowed\n",
    "# yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.filter(yellow_data_2019_wtemp_and_time.date >= \\\n",
    "#                                                                          datetime.datetime.timestamp(\"2019-01-01\"))\n",
    "\n",
    "\n",
    "\n",
    "# yellow_data_2019.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9efc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make area code a categorical variable\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.withColumn('PULocationID', \n",
    "                                                                             yellow_data_2019_wtemp_and_time.PULocationID.cast('string'))\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.withColumn('PULocationID', \n",
    "                                                                             jan_yellow_sdf_2020_wtemp_and_time.PULocationID.cast('string'))\n",
    "\n",
    "# make maxTemp an int type\n",
    "yellow_data_2019_wtemp_and_time = yellow_data_2019_wtemp_and_time.withColumn('maxTemp', \n",
    "                                                                             yellow_data_2019_wtemp_and_time.PULocationID.cast('int'))\n",
    "jan_yellow_sdf_2020_wtemp_and_time = jan_yellow_sdf_2020_wtemp_and_time.withColumn('maxTemp', \n",
    "                                                                             jan_yellow_sdf_2020_wtemp_and_time.PULocationID.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b3fe274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yellow_data_2019_wtemp_and_time.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9143f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan_yellow_sdf_2020_wtemp_and_time.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d99ed2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(date,DateType,true),StructField(VendorID,IntegerType,true),StructField(tpep_pickup_datetime,TimestampType,true),StructField(tpep_dropoff_datetime,TimestampType,true),StructField(passenger_count,IntegerType,true),StructField(trip_distance,DoubleType,true),StructField(RatecodeID,IntegerType,true),StructField(store_and_fwd_flag,StringType,true),StructField(PULocationID,StringType,true),StructField(DOLocationID,IntegerType,true),StructField(payment_type,IntegerType,true),StructField(fare_amount,DoubleType,true),StructField(extra,DoubleType,true),StructField(mta_tax,DoubleType,true),StructField(tip_amount,DoubleType,true),StructField(tolls_amount,DoubleType,true),StructField(improvement_surcharge,DoubleType,true),StructField(total_amount,DoubleType,true),StructField(congestion_surcharge,DoubleType,true),StructField(trip_time,IntegerType,true),StructField(maxTemp,IntegerType,true)))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yellow_data_2019_wtemp_and_time.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9ea39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = yellow_data_2019_wtemp_and_time.select('trip_distance', 'trip_time', 'maxTemp', 'fare_amount')\n",
    "test_data = jan_yellow_sdf_2020_wtemp_and_time.select('trip_distance', 'trip_time', 'maxTemp', 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57a4ff77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trip_distance', 'trip_time', 'maxTemp']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = training_data.columns[0:3]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21551c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vecAssembler = VectorAssembler(outputCol=\"features\")\n",
    "vecAssembler.setInputCols(columns)\n",
    "\n",
    "output = vecAssembler.transform(training_data)\n",
    "final_df = output.select('features', 'fare_amount')\n",
    "\n",
    "output_test = vecAssembler.transform(test_data)\n",
    "final_test = output_test.select('features', 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b38b2e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/08/14 15:27:26 WARN Instrumentation: [2d6e58e5] regParam is zero, which might cause numerical instability and overfitting.\n",
      "21/08/14 15:27:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/08/14 15:27:27 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "21/08/14 15:52:49 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "21/08/14 15:52:49 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>1.867850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_time</th>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxTemp</th>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficients\n",
       "trip_distance      1.867850\n",
       "trip_time          0.006048\n",
       "maxTemp            0.000024"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "lm = LinearRegression(labelCol='fare_amount')\n",
    "model = lm.fit(final_df)\n",
    "pd.DataFrame({\"Coefficients\": model.coefficients}, index=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d7514fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "242d0f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|  -0.057606074323588|\n",
      "|-0.00714043155606...|\n",
      "|  0.5611334058348714|\n",
      "| 0.17139044038055928|\n",
      "| 0.05451213120390941|\n",
      "|   0.463041367260443|\n",
      "| -0.6778511430152268|\n",
      "|  0.6956665329775067|\n",
      "|-0.41105371346384345|\n",
      "|-0.10649381223199406|\n",
      "| -1.6138240713914378|\n",
      "| -0.2413829802489431|\n",
      "|-0.10894508973362527|\n",
      "| 0.10545255535871512|\n",
      "|  0.4274580390690126|\n",
      "|-0.12816788284072622|\n",
      "|   1.096279502344153|\n",
      "| -0.5179477987387653|\n",
      "| -0.5330788208833006|\n",
      "|-0.24057673524163192|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff23b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
